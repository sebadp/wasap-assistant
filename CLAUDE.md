# WasAP â€” Convenciones del Proyecto

> **Mapa del proyecto** â†’ `AGENTS.md` (dÃ³nde estÃ¡ cada cosa, workflow, skills activos)
> Este archivo documenta **convenciones de cÃ³digo y patrones arquitectÃ³nicos**.

## Protocolo de DocumentaciÃ³n (OBLIGATORIO al terminar una feature)

### Documentos a crear/actualizar
1. Crear `docs/features/<nombre>.md` (template: `docs/features/TEMPLATE.md`)
2. Crear `docs/testing/<nombre>_testing.md` (template: `docs/testing/TEMPLATE.md`)
3. Actualizar `docs/features/README.md` y `docs/testing/README.md` con la nueva entrada
4. Actualizar `CLAUDE.md` con patrones que deben preservarse
5. Actualizar `AGENTS.md` si se agrega un skill, mÃ³dulo o comando nuevo

### Exec Plans (para features complejas)
- Crear `docs/exec-plans/<nombre>.md` **antes** de implementar si se afectan â‰¥3 archivos
- El plan es artefacto de primera clase: documenta **decisiones**, no solo pasos
- Incluir siempre: objetivo, archivos a modificar, schema de datos, orden de implementaciÃ³n
- Marcar el estado al terminar: ðŸ“‹ Pendiente â†’ ðŸš§ En progreso â†’ âœ… Completado
- Ver convenciones detalladas y planes existentes: [`docs/exec-plans/README.md`](docs/exec-plans/README.md)

## Stack
- **Framework**: FastAPI (async, lifespan pattern)
- **LLM**: Ollama con **qwen3:8b** (chat) y **llava:7b** (vision)
- **Audio**: faster-whisper (transcripcion local)
- **DB**: SQLite via aiosqlite + sqlite-vec (vector search)
- **Embeddings**: nomic-embed-text via Ollama (768 dims)
- **Python**: 3.11+

## Modelos de Ollama
- Chat principal: `qwen3:8b` â€” NO usar qwen2.5
- Vision: `llava:7b`
- Los defaults estan en `app/config.py`, overrideables via env vars
- `think: True` solo para qwen3 sin tools. Cuando hay tools en el payload, NO se usa `think`

## Estructura
```
app/
  main.py              # FastAPI app + lifespan + scheduler jobs
  guardrails/          # ValidaciÃ³n pre-entrega (Eval Fase 1)
    models.py          # GuardrailResult, GuardrailReport
    checks.py          # check_not_empty, check_language_match, check_no_pii, etc.
    pipeline.py        # run_guardrails() â€” orquesta checks, fail-open
  tracing/             # Trazabilidad estructurada (Eval Fase 2)
    context.py         # TraceContext (async ctx mgr), SpanData, get_current_trace()
    recorder.py        # TraceRecorder â€” persistencia SQLite best-effort
  context/             # Context engineering (Fase 5)
    fact_extractor.py  # ExtracciÃ³n de user_facts con regex (sin LLM)
    conversation_context.py  # ConversationContext dataclass + build()
  config.py            # Settings (pydantic-settings, .env)
  models.py            # Pydantic models
  dependencies.py      # FastAPI dependency injection
  logging_config.py    # JSON structured logging
  embeddings/          # Embedding indexer
    indexer.py         # embed_memory, backfill_embeddings (best-effort)
  llm/client.py        # OllamaClient (chat + tool calling + embeddings)
  whatsapp/client.py   # WhatsApp Cloud API client
  webhook/router.py    # Webhook endpoints + _handle_message + graceful shutdown
  webhook/parser.py    # Extrae mensajes del payload (text, audio, image, reply context)
  webhook/security.py  # HMAC signature validation
  webhook/rate_limiter.py
  audio/transcriber.py # faster-whisper wrapper
  formatting/
    markdown_to_wa.py  # Markdown â†’ WhatsApp
    splitter.py        # Split mensajes largos
    compaction.py      # JSON-aware compaction (3 niveles: JSON â†’ LLM â†’ truncate)
  skills/              # Sistema de skills y tool calling
    models.py          # ToolDefinition, ToolCall, ToolResult, SkillMetadata
    loader.py          # Parser de SKILL.md (frontmatter con regex, sin PyYAML)
    registry.py        # SkillRegistry â€” registro, schemas Ollama, ejecuciÃ³n
    executor.py        # Tool calling loop + _clear_old_tool_results
    router.py          # classify_intent, select_tools, TOOL_CATEGORIES
    tools/             # Handlers de tools builtin
      datetime_tools.py
      calculator_tools.py
      weather_tools.py
      notes_tools.py
      selfcode_tools.py
      expand_tools.py
      project_tools.py
  agent/               # Modo agÃ©ntico
    loop.py            # Outer agent loop (rounds Ã— tool calls), task plan injection
    models.py          # AgentSession, AgentStatus
    hitl.py            # Human-in-the-loop (request_user_approval)
    task_memory.py     # create_task_plan, update_task_status, get_task_plan
  commands/            # Sistema de comandos (/remember, /forget, etc)
  conversation/        # ConversationManager + Summarizer
  database/            # SQLite init + sqlite-vec + Repository
  memory/              # Sistema de memoria
    markdown.py        # Sync bidireccional SQLite â†” MEMORY.md
    watcher.py         # File watcher (watchdog) para ediciÃ³n manual de MEMORY.md
    daily_log.py       # Daily logs append-only + session snapshots
    consolidator.py    # Dedup/merge de memorias via LLM
  eval/                # Dataset vivo + curaciÃ³n automÃ¡tica
    dataset.py         # maybe_curate_to_dataset() (3-tier), add_correction_pair()
    exporter.py        # export_to_jsonl() para tests offline
  mcp/                 # MCP server integration
skills/                # SKILL.md definitions (configurable via skills_dir)
tests/
```

## Tests
- Correr: `make test` o `.venv/bin/python -m pytest tests/ -v`
- `asyncio_mode = "auto"` â€” no hace falta `@pytest.mark.asyncio`
- `TestClient` (sync) para integration tests del webhook
- Async fixtures para unit tests
- Mockear siempre Ollama y WhatsApp API en tests

## Calidad de cÃ³digo
- **Linter**: `ruff` â€” `make lint` / `make format`
- **Type checking**: `mypy app/` â€” `make typecheck` (solo `app/`, no `tests/`)
- **Pre-commit hooks**: ruff â†’ mypy â†’ pytest â€” instalar con `make dev`
- **CI**: GitHub Actions en `.github/workflows/ci.yml` â€” 3 jobs: lint â†’ typecheck â†’ test
- **mypy lenient**: `ignore_missing_imports = true` porque faster-whisper, sqlite-vec, mcp, watchdog no tienen stubs
- **ruff ignores**: `E501` (lineas largas), `B008` (FastAPI usa `Depends(...)` como default)
- Antes de pushear: `make check` (lint + typecheck + tests)

## Performance â€” Critical Path en `_handle_message`

El procesamiento de cada mensaje estÃ¡ paralelizado en fases:

| Fase | QuÃ© corre en paralelo (asyncio.gather) | Bloqueante |
|------|----------------------------------------|-----------|
| **Phase A** | embed(query) â€– save_message \| load_daily_logs | SÃ­ |
| **Phase B** | search_memories â€– search_notes â€– get_summary â€– get_recent_messages â€– get_projects_summary | SÃ­ |
| **Phase C** | await classify_task + load sticky_categories + extract user_facts | SÃ­ |
| **Phase D** | `_build_context()` (sync) â†’ LLM principal | SÃ­ |

- `classify_intent` se lanza como `asyncio.create_task` antes de Phase A â€” corre en paralelo con las fases I/O-bound. Si retorna `"none"`, se re-clasifica con contexto (historial + sticky categories).
- `_build_context()` en router.py â€” construye el contexto LLM a partir de datos pre-fetched, sin DB calls.
- `pre_classified_categories` en `execute_tool_loop` â€” evita segunda llamada a `classify_intent`.
- Cache module-level `_cached_tools_map` en executor.py â€” construye el map de tools una vez.
- Tool calls en paralelo dentro de una iteraciÃ³n: `asyncio.gather(*[_run_tool_call(...)])` .
- WA calls iniciales (mark_as_read + send_reaction) paralelizadas con `asyncio.gather`.
- Blocking I/O en `daily_log.py` y `markdown.py` â†’ `asyncio.to_thread()` (stdlib Python 3.9+).
- Cache de conv_id en `ConversationManager._conv_id_cache` (dict phoneâ†’id, permanente durante runtime).
- `get_active_memories(limit=...)` â€” fallback con lÃ­mite (`settings.semantic_search_top_k`).
- SQLite PRAGMA tuning en `db.py`: `synchronous=NORMAL`, `cache_size=-32000` (32MB), `temp_store=MEMORY`.
- Model warmup en `main.py` startup: `embed(["warmup"]) â€– chat_with_tools([...])` â€” non-critical, wrapped en try/except.


## Patrones
- Todo async, nunca bloquear el event loop (usar `run_in_executor` para sync code como Whisper)
- Background tasks via `BackgroundTasks` de FastAPI, trackeados con `_track_task()` para graceful shutdown
- Dependencies via `app.state.*` + funciones `get_*()` en `dependencies.py`
- Mensajes de WhatsApp se formatean (markdown->whatsapp) y splitean antes de enviar
- Tool calling loop: LLM llama tools â†’ se ejecutan â†’ resultados vuelven al LLM â†’ repite hasta texto o max 5 iteraciones
- Dedup atomico: `processed_messages` tabla con INSERT OR IGNORE (sin race conditions)
- Reply context: si el usuario responde a un mensaje, se inyecta el texto citado en el prompt
- `_build_capabilities_section()` en router.py construye secciÃ³n estructurada de capacidades (commands + skills + MCP) para el contexto LLM â€” reemplaza el summary plano anterior. Se auto-actualiza al agregar skills/commands/MCP servers
- SKILL.md: frontmatter parseado con regex (sin PyYAML), instrucciones se cargan lazy en primer uso
- `selfcode` skill: `register()` recibe `settings` (no `repository`). `_PROJECT_ROOT` resuelto una sola vez al importar. `_is_safe_path()` previene path traversal + bloquea archivos sensibles. `_SENSITIVE` hardcodeado oculta tokens de WhatsApp en `get_runtime_config`. `register_builtin_tools` acepta `settings=None` â€” selfcode solo se registra si `settings` no es None
- Hot-reload: `McpManager` usa `_server_stacks: dict[str, AsyncExitStack]` (uno por servidor) en lugar de un stack global â€” permite `hot_add_server()` / `hot_remove_server()` sin restart. `hot_add_server` persiste config + llama `reset_tools_cache()` + `register_dynamic_category()`. `SkillRegistry.reload()` re-escanea `skills/` y limpia `_loaded_instructions`. `reset_tools_cache()` en executor.py pone `_cached_tools_map = None`
- MCP HTTP transport: `McpManager._connect_server()` detecta `cfg["type"]` â€” `"http"` usa `streamable_http_client(url)` (3-tuple read/write/session_id), `"stdio"` usa `stdio_client` (2-tuple). Servidores Smithery son siempre tipo `"http"`
- `expand` skill: `register()` recibe `mcp_manager` (no `repository`). MCP manager se inicializa ANTES que skills en `main.py` para que `expand_tools` pueda referenciar el manager. Smithery API: `GET https://registry.smithery.ai/servers?q=<query>` â€” no requiere auth
- Guardrails LLM checks (IteraciÃ³n 6): `check_tool_coherence` y `check_hallucination` en `checks.py` â€” async, prompt binario (yes/no), fail open. Integrados via `_run_async_check(timeout=0.5s)` en `pipeline.py`. Gated por `guardrails_llm_checks=False` (opt-in). Call site en `router.py` pasa `ollama_client` a `run_guardrails`.
- Span instrumentation de tools: `_run_tool_call` en `executor.py` llama `get_current_trace()` â€” si hay traza activa, wrappea ejecuciÃ³n en `trace.span(f"tool:{name}", kind="tool")` con input/output. Sin traza â†’ ejecuciÃ³n directa sin overhead.
- Trace cleanup job: APScheduler cron 03:00 UTC registrado en `main.py` gated por `tracing_enabled`. Closure sobre `repository` + `settings`. Llama `repository.cleanup_old_traces(days=settings.trace_retention_days)`.
- Dashboard queries eval: `repository.get_failure_trend(days)` (tendencia diaria) + `repository.get_score_distribution()` (stats por check). Tool `get_dashboard_stats` en eval skill.
- Calculator: AST safe eval con whitelist estricta, NO eval() directo
- Docker: container corre como `appuser` (UID=1000), no root
- Memoria en 3 capas: semÃ¡ntica (MEMORY.md), episÃ³dica reciente (daily logs), episÃ³dica histÃ³rica (snapshots)
- Pre-compaction flush: antes de borrar mensajes, el LLM extrae factsâ†’memories + eventsâ†’daily log
- Dedup de facts: `difflib.SequenceMatcher(ratio > 0.8)` contra memorias existentes
- Session snapshots: `/clear` guarda Ãºltimos 15 msgs con slug LLM-generated en `data/memory/snapshots/`
- Memory consolidation: LLM revisa memorias para duplicados/contradicciones despuÃ©s del flush
- `/review-skill` command: sin args lista skills + MCP servers; con nombre muestra detalle (tools, estado, instrucciones para skills; tipo, estado, tools para MCP)
- `CommandContext` tiene `ollama_client`, `daily_log` y `embed_model` para snapshot generation y auto-indexing
- BÃºsqueda semÃ¡ntica: `_get_query_embedding()` se computa una vez y se reutiliza para memorias + notas
- `init_db()` retorna `(conn, vec_available)` â€” fallback graceful si sqlite-vec no disponible
- sqlite-vec: `check_same_thread=False` + `conn._connection.enable_load_extension()` durante init
- Vectores serializados con `struct.pack(f"{len(v)}f", *v)` para blob storage
- Embeddings best-effort: errores logueados, nunca propagados â€” la app funciona sin embeddings
- MEMORY.md watcher: watchdog con sync guard (`threading.Event`) para prevenir loops
- `MemoryFile.set_watcher()` conecta el guard; `on_created` maneja editores con atomic rename
- `projects` skill: 4 tablas (`projects`, `project_tasks`, `project_activity`, `project_notes`) + `vec_project_notes` (sqlite-vec). `phone_number` en `projects` (no FK a `conversations`) â€” proyectos sobreviven `/clear`. `UNIQUE(phone_number, name)` â€” el LLM identifica proyectos por nombre. `project_tools.register()` recibe `repository`, `daily_log`, `ollama_client`, `embed_model`, `vec_available`. `set_current_user(phone)` module-level seteado per-request en `_handle_message`. `_resolve_project(name)` helper interno que busca COLLATE NOCASE. `update_task` a "done" loguea al `daily_log`. Si todas las tareas estÃ¡n done â†’ sugiere `update_project_status`. `update_project_status` a archived/completed â†’ registra resumen final automÃ¡tico. `_get_active_projects_summary()` en webhook/router.py â€” inyectada en Phase B (`asyncio.gather` con memorias/notas/summary/history). `register_builtin_tools` acepta `daily_log=None` â€” pasado desde `main.py`. Embeddings de project notes via `embed_project_note()` en indexer.py (best-effort). BÃºsqueda semÃ¡ntica en `search_project_notes` con fallback a list all.
- **Guardrails** (`app/guardrails/`): pipeline de validaciÃ³n pre-entrega. Checks determinÃ­sticos (sin LLM): `not_empty`, `language_match` (solo si â‰¥30 chars â€” `langdetect` falla en textos cortos), `no_pii`/`redact_pii` (regex), `excessive_length` (>8000 chars), `no_raw_tool_json`. Fail-open: errores en checks â†’ pasan. Remediation single-shot en `_handle_guardrail_failure` (sin recursiÃ³n). Scores de guardrails â†’ `trace_scores` (value=1.0/0.0, source="system"). Integrado en `_run_normal_flow()` dentro de `_handle_message`.
- **Trazabilidad** (`app/tracing/`): `TraceContext` usa `contextvars.ContextVar` â€” sub-tasks de asyncio heredan el trace automÃ¡ticamente sin cambiar firmas. `TraceRecorder` best-effort (excepciones capturadas, nunca propagadas). `TRACING_SCHEMA` en `db.py` crea tablas `traces`, `trace_spans`, `trace_scores` con `CREATE TABLE IF NOT EXISTS`. `WhatsAppClient.send_message()` retorna `str | None` (wa_message_id del primer chunk) para vincular trazas a mensajes WA. Flujo normal refactorizado en `_run_normal_flow()` inner function en `router.py` â€” permite toggle de tracing sin duplicar lÃ³gica. `tracing_sample_rate` check con `random.random()` antes de crear el `TraceContext` (sampling a nivel de mensaje completo).
- **Dataset vivo** (`app/eval/`): `DATASET_SCHEMA` en `db.py` â€” tablas `eval_dataset` + `eval_dataset_tags` (tags como tabla join separada, no JSON array â€” permite Ã­ndices eficientes). CuraciÃ³n 3-tier en `maybe_curate_to_dataset()`: failure (guardrail<0.3 o usuario negativo) > golden confirmado (sistema OK + usuario positivo) > golden candidato (sistema OK, sin seÃ±al de usuario, `metadata.confirmed=False`). Se llama como background task al final de `_run_normal_flow()` cuando `eval_auto_curate=True`. Correction pairs: `add_correction_pair()` guarda `entry_type="correction"` con `expected_output=correction_text` al detectar correcciÃ³n high-confidence (score==0.0). FK de `eval_dataset.trace_id` â†’ `traces(id)` enforced con `PRAGMA foreign_keys=ON`. `exporter.py`: `export_to_jsonl()` exporta a JSONL para tests offline.
- **Auto-evoluciÃ³n** (`app/eval/prompt_manager.py` + `app/eval/evolution.py`): `PROMPT_SCHEMA` en `db.py` â€” tabla `prompt_versions` (unique index por `prompt_name+version`, constraint `is_active` enforced a nivel app en `activate_prompt_version()` â€” SQLite no soporta partial unique index). Cache en memoria `_active_prompts` dict en `prompt_manager.py` â€” se invalida vÃ­a `invalidate_prompt_cache()`. `get_active_prompt()` lazy-loads desde DB, fallback al default de `config.py`. Integrado en `_run_normal_flow()` reemplazando `settings.system_prompt`. Memorias de auto-correcciÃ³n: guardrail failure â†’ `_save_self_correction_memory()` background task â†’ `add_memory(category="self_correction")` + cooldown 2h por tipo de check + TTL 24h. `propose_prompt_change()` en `evolution.py`: LLM genera prompt modificado â†’ `save_prompt_version(created_by="agent")`. Comando `/approve-prompt <nombre> <versiÃ³n>` â†’ `activate_prompt_version()` + `invalidate_prompt_cache()`.
- **Eval skill** (`skills/eval/SKILL.md` + `app/skills/tools/eval_tools.py`): 8 tools â€” `get_eval_summary` (mÃ©tricas agregadas de scores), `list_recent_failures` (trazas con score<0.5), `diagnose_trace` (deep-dive con spans y scores), `propose_correction` (correction pair vÃ­a LLM), `add_to_dataset` (curaciÃ³n manual), `get_dataset_stats` (composiciÃ³n del dataset), `run_quick_eval` (eval offline usando `ollama_client.chat()` directo â€” SIN tool loop para evitar recursiÃ³n). Registrado en `register_builtin_tools()` con guard `settings.tracing_enabled`. CategorÃ­a `"evaluation"` agregada a `TOOL_CATEGORIES` en `app/skills/router.py` â€” el classifier dinÃ¡micamente incluye la categorÃ­a (usa `TOOL_CATEGORIES.keys()`). PatrÃ³n: closures sobre `repository` + `ollama_client` dentro de `register()`, igual que `selfcode_tools.py`.
- **Context Engineering** (`app/context/`, `app/formatting/compaction.py`, `app/webhook/router.py`, `app/agent/loop.py`): sticky categories persisten en tabla `conversation_state` â€” categorÃ­as del turno anterior se usan como fallback si `classify_intent` retorna `"none"`. `user_facts` (github_username, name, etc.) se extraen de memorias con regex en `fact_extractor.py` e inyectan como system message al tool loop. `_clear_old_tool_results(keep_last_n=2)` en executor.py resume tool results viejos. `compact_tool_output()` usa JSON-aware extraction antes del LLM â€” preserva nombres/IDs exactos. `self_correction` category solo en DB, excluida de MEMORY.md sync. Agente con loop externo en `agent/loop.py` (15 rounds Ã— 8 tools), task plan re-inyectado entre rounds, completion via `[ ]` pendientes en task plan. Ver: [`docs/features/08-context_engineering.md`](docs/features/08-context_engineering.md)
